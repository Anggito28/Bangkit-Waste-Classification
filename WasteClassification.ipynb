{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cardstdani/WasteClassificationNeuralNetwork/blob/main/WasteClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2bF-7GjomcU",
    "outputId": "d85e73a6-ccac-487c-8f76-53cf75cbf4bc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 31 13:25:41 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.68                 Driver Version: 531.68       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti    WDDM | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P0               13W /  N/A|      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uKJADf8Dj1wx"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import cv2 as cv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgxnpfh-nwT8"
   },
   "source": [
    "##**Data Gathering and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BglZv46nj-fC",
    "outputId": "64a792d1-5174-4e13-ef9d-e8e510842f16"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/cardstdani/WasteClassificationNeuralNetwork.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZBRyLMNldS6",
    "outputId": "5ecf0486-f70c-4720-e388-a72bc326e639"
   },
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "DIR = \"./WasteImagesDataset\"\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(DIR, validation_split=0.1, subset=\"training\", seed=42, batch_size=128, smart_resize=True, image_size=(256, 256))\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(DIR, validation_split=0.1, subset=\"validation\", seed=42, batch_size=128, smart_resize=True, image_size=(256, 256))\n",
    "\n",
    "classes = train_dataset.class_names\n",
    "numClasses = len(train_dataset.class_names)\n",
    "print(classes)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn75v-H1nzwl"
   },
   "source": [
    "##**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAF6I0e4hL4f",
    "outputId": "e227cdb2-7ef7-4189-e250-9713b6c29bc9"
   },
   "outputs": [],
   "source": [
    "baseModel = tf.keras.applications.MobileNetV3Large(input_shape=(256, 256,3), weights='imagenet', include_top=False, classes=numClasses)\n",
    "for layers in baseModel.layers[:-6]:\n",
    "  layers.trainable=False\n",
    "\n",
    "last_output = baseModel.layers[-1].output\n",
    "x = tf.keras.layers.Dropout(0.45) (last_output)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization() (x)\n",
    "x = tf.keras.layers.Dense(256, activation = tf.keras.activations.elu, kernel_regularizer=tf.keras.regularizers.l1(0.045), activity_regularizer=tf.keras.regularizers.l1(0.045),  kernel_initializer='he_normal')(x)\n",
    "x = tf.keras.layers.Dropout(0.45) (x)\n",
    "x = tf.keras.layers.Dense(numClasses, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=baseModel.input,outputs=x)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00125), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "lrCallback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10 ** (epoch / 30))\n",
    "stepDecay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.1 * 0.1**math.floor(epoch / 6))\n",
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXEnwpldpEu0",
    "outputId": "2be290ee-7abc-4626-9595-65f7e4b9fca2"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3H0LZIsn2k4"
   },
   "source": [
    "##**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "qZ17uEZImt-c",
    "outputId": "e8f24a24-99ef-4abd-e695-2fc9873b1d59"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(0, epochs), history.history[\"loss\"], color=\"b\", label=\"Loss\")\n",
    "plt.plot(range(0, epochs), history.history[\"val_loss\"], color=\"r\", label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "yutf5bmFmwoZ",
    "outputId": "2b2607cc-f3ca-46f1-b20f-d5e4b2de53b6"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(0, epochs), history.history[\"accuracy\"], color=\"b\", label=\"Accuracy\")\n",
    "plt.plot(range(0, epochs), history.history[\"val_accuracy\"], color=\"r\", label=\"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "7mEM1Zuwno5M",
    "outputId": "978f343f-b276-4415-f40d-a9d781089be1"
   },
   "outputs": [],
   "source": [
    "plt.xlim([0, 0.003])\n",
    "learning_rates = 1e-3 * (10 ** (np.arange(epochs) / 30))\n",
    "plt.plot(learning_rates, history.history['loss'], lw=3, color='#48e073')\n",
    "plt.title('Learning rate vs. loss', size=20)\n",
    "plt.xlabel('Learning rate', size=14)\n",
    "plt.ylabel('Loss', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "owXEpurFmh_g",
    "outputId": "4168f0a1-d89d-437a-e335-542d2893ce69"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "img_data = requests.get(\"https://images.unsplash.com/photo-1591872203534-278fc084969e?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1064&q=80\").content\n",
    "with open('img.jpg', 'wb') as handler:\n",
    "    handler.write(img_data)\n",
    "\n",
    "path = \"/content/img.jpg\"\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(path, target_size=(256, 256))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) \n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "plt.imshow(img)\n",
    "print(predictions[0]*100, \"\\n\", classes)\n",
    "print(\"Prediction: \", classes[np.argmax(predictions)], f\"{predictions[0][np.argmax(predictions)]*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "EmTBuKN0mpsu",
    "outputId": "d9c8016f-70f5-46cc-ab2e-2a69926a4e6c"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names, cmap=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}%; misclass={:0.4f}%'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "true = []\n",
    "predictions = []\n",
    "\n",
    "\"\"\"\n",
    "for images, labels in test_dataset.take(50):\n",
    "  pred = model.predict(images)\n",
    "  for i in range(32):\n",
    "    try:\n",
    "      ax = plt.subplot(4, 8, i + 1)\n",
    "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "      #print(classes[np.argmax(pred[i])], 100 * np.max(pred[i]), \"real = \" + str(classes[labels[i]]))\n",
    "\n",
    "      true.append(labels[i])\n",
    "      predictions.append(np.argmax(pred[i]))\n",
    "\n",
    "      plt.title(classes[labels[i]])\n",
    "      plt.axis(\"off\")\n",
    "    except:\n",
    "      print()\n",
    "\n",
    "\"\"\"\n",
    "path = \"/content/WasteClassificationNeuralNetwork/WasteImagesDataset\"\n",
    "for i in os.listdir(path):\n",
    "  folderPath = os.path.join(path, i)\n",
    "  for j in os.listdir(folderPath)[:550]:\n",
    "    fullPath = os.path.join(folderPath, j)\n",
    "    try:\n",
    "      img = tf.keras.preprocessing.image.load_img(fullPath, target_size=(256, 256))\n",
    "      img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "      img_array = tf.expand_dims(img_array, 0) \n",
    "\n",
    "      preds = model.predict(img_array)\n",
    "      true.append(classes.index(i))\n",
    "      predictions.append(np.argmax(preds))\n",
    "    except:\n",
    "      print(\"Error on image:\", fullPath)\n",
    "\n",
    "plot_confusion_matrix(tf.math.confusion_matrix(true, predictions), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LprfEaEvnoqV"
   },
   "source": [
    "**Advanced Filter Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "df4Mof98nn8j",
    "outputId": "ecb32e7d-94d9-412e-a92e-cabc68659fea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import imutils\n",
    "\n",
    "class GradCAM:\n",
    "  def __init__(self, model, classIdx, layerName=None):\n",
    "    self.model = model\n",
    "    self.classIdx = classIdx\n",
    "    self.layerName = layerName\n",
    "    if self.layerName is None:\n",
    "      self.layerName = self.find_target_layer()\n",
    "   \n",
    "  def find_target_layer(self):\n",
    "    for layer in reversed(self.model.layers):\n",
    "      if len(layer.output_shape) == 4:\n",
    "        return layer.name\n",
    "    raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
    "\n",
    "  def compute_heatmap(self, image, eps=1e-8):\n",
    "    gradModel = Model(\n",
    "\t\t\tinputs=[self.model.inputs],\n",
    "\t\t\toutputs=[self.model.get_layer(self.layerName).output,\n",
    "\t\t\t\tself.model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "      inputs = tf.cast(image, tf.float32)\n",
    "      (convOutputs, predictions) = gradModel(inputs)\n",
    "      loss = predictions[:, self.classIdx]\n",
    "    grads = tape.gradient(loss, convOutputs)\n",
    "    castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "    castGrads = tf.cast(grads > 0, \"float32\")\n",
    "    guidedGrads = castConvOutputs * castGrads * grads\n",
    "    convOutputs = convOutputs[0]\n",
    "    guidedGrads = guidedGrads[0]\n",
    "    weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "    (w, h) = (image.shape[2], image.shape[1])\n",
    "    heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "    numer = heatmap - np.min(heatmap)\n",
    "    denom = (heatmap.max() - heatmap.min()) + eps\n",
    "    heatmap = numer / denom\n",
    "    heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "    return heatmap\n",
    "\n",
    "  def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_VIRIDIS):\n",
    "    heatmap = cv2.applyColorMap(heatmap, colormap)\n",
    "    output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
    "    return (heatmap, output)\n",
    "\n",
    "path = \"/content/img.jpg\"\n",
    "orig = cv2.imread(path)\n",
    "resized = cv2.resize(orig, (256, 256))\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img(path, target_size=(256, 256))\n",
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "predictions = model.predict(image)\n",
    "cam = GradCAM(model, np.argmax(predictions[0]), \"expanded_conv_6/expand\")\n",
    "heatmap = cv2.resize(cam.compute_heatmap(image), (orig.shape[1], orig.shape[0]))\n",
    "\n",
    "#heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n",
    "(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)\n",
    "\n",
    "#cv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)\n",
    "cv2.putText(output, classes[np.argmax(predictions)], (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "output = np.vstack([orig, heatmap, output])\n",
    "output = imutils.resize(output, height=700)\n",
    "cv2_imshow(output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "WasteClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
